# Omni LinkedIn Enrichment Pipeline

This project enriches people data from a CSV (e.g. Airtable export) using LinkedIn profiles and LLM-generated summaries & interests. It supports scrapers like **BrightData**, includes local caching to reduce costs, and allows LLM or manual processing.

---

## âš™ï¸ Setup

### 1. Install dependencies

Install via [`uv`](https://github.com/astral-sh/uv):

```bash
uv sync
source .venv/bin/activate
```

> ğŸ’¡ Make sure your `.venv` is already created (`uv venv` not required in this repo).

---

### 2. Configure your environment

Copy the `.env` example and edit it with your API keys:

```bash
cp .env.example .env
```

Youâ€™ll need to set your **scraper** (e.g. BrightData), your **OpenAI/Gemini keys**, and optionally Airtable parameters (not yet used automatically).

See `.env.example` for all fields.

---

### 3. Prepare your CSV input

Export your Airtable manually to:

```
data/airtable_export.csv
```

The file should look like:

```csv
PrÃ©nom,Nom,Email,Organisation,Titre,MÃ©tier,IntÃ©rÃªt,Domain,Tags,Statut,Description,Linkedin
Alice,Dupont,alice@example.com,Acme Corp,Lead AI,data scientist,,Tech,,Member,,https://www.linkedin.com/in/alice-dupont/
Bob,Martin,bob@example.org,Omnitech,ML Ops Engineer,mlops engineer,,Tech,,Pending,,https://www.linkedin.com/in/bob-martin/
```

âœ… **If `Linkedin` URL is missing**, the script will fall back to job title/domain for enrichment only.

---

## ğŸš€ Enrichment Options

### Option 1 â€“ Full batch CSV enrichment

```bash
python src/enrich_from_csv.py
```

This will:

* Read `data/airtable_export.csv`
* Scrape and cache LinkedIn data
* Generate `IntÃ©rÃªt` and `Description` using manual or LLM-based logic
* Output to `data/enriched_output.csv`
* Cache raw LinkedIn JSON to `data/fetched_json/`

---

### Option 2 â€“ Try the flow manually

```bash
python src/main.py [manual|llm]
```

Run a single test profile through the logic:

```bash
python src/main.py llm
```

Uses a hardcoded profile with `"summary"`, `"headline"`, and `"experience"` to demonstrate tag extraction & description generation.

---

## ğŸ“ Project Structure

```
data/
  airtable_export.csv             â† CSV input (manual download from Airtable)
  enriched_output.csv             â† Enriched output
  fetched_json/                   â† Cached LinkedIn snapshot data (JSON)

src/
  enrich_from_csv.py              â† Main pipeline runner
  main.py                         â† Manual test run for a single profile
  adapters/
    linkedin_scraper_adapter.py   â† Dynamic scraper loader
  scrapers/
    brightdata_scraper.py         â† BrightData implementation
  core/
    pipeline.py                   â† LLM logic and tag generation
    schema.py                     â† Pydantic validation schemas
    static_values.py              â† Constants and allowed interest tags
  services/
    llm_interface.py              â† Interface for OpenAI or Gemini
    tag_description_builder.py    â† Manual rule-based tag system
  utils/
    crud.py                       â† Helper to flatten LinkedIn data
```

---

## ğŸ’¡ Features

* ğŸ”€ **LLM or manual tag extraction** (`llm` or `manual` via env or CLI)
* ğŸš« **Tag validation & cleaning** (invalid tags are logged and ignored)
* ğŸ’¾ **Local cache** of scraped data (avoids redundant API calls)
* ğŸ”Œ **BrightData support** (snapshot polling and JSON saving)

---

## ğŸ“Œ .env.example overview

```dotenv
# Select scraper
SCRAPER_TYPE=brightdata

# BrightData
BRIGHTDATA_API_KEY=your_key
BRIGHTDATA_DATASET_ID=your_dataset_id
BRIGHTDATA_TIMEOUT=120
BRIGHTDATA_POLL_INTERVAL=5

# Proxycurl (optional)
PROXYCURL_API_KEY=your_key

# LLM Providers
OPENAI_API_KEY=your_openai_key
GEMINI_API_KEY=your_gemini_key

# Output
OUTPUT_DIRECTORY=./data/profiles
LOG_DIRECTORY=./data/logs
BATCH_LIMIT=5
```

---

## ğŸ›‘ Disclaimer

This tool fetches public LinkedIn data using external APIs. You must comply with the terms of service of BrightData, LinkedIn, OpenAI, and other services used.

---

## ğŸ“† Roadmap

* [ ] ğŸ”Œ Add automatic Airtable sync
* [ ] ğŸ§  Add smarter tag suggestion (embeddings / clustering)
* [ ] ğŸ” Enable retry queue for failed fetches

---